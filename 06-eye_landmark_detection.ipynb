{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install dlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Fwrq4nzovcH",
        "outputId": "5081b9ef-c7e6-4d7a-d912-a35b4d77792b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dlib in /usr/local/lib/python3.10/dist-packages (19.24.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import shutil\n",
        "import bz2"
      ],
      "metadata": {
        "id": "meiY5OB3rMdb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download the shape predictor model file from the dlib repository**"
      ],
      "metadata": {
        "id": "mOaZdZvRrTDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Downloading shape predictor model file...\")\n",
        "model_url = \"http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\"\n",
        "model_path_bz2 = \"/content/shape_predictor_68_face_landmarks.dat.bz2\"\n",
        "model_path_dat = \"/content/shape_predictor_68_face_landmarks.dat\"\n",
        "urllib.request.urlretrieve(model_url, model_path_bz2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVlFDprRrU3U",
        "outputId": "30925f53-c45d-48a2-e418-dbb6c8cc4c83"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading shape predictor model file...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/shape_predictor_68_face_landmarks.dat.bz2',\n",
              " <http.client.HTTPMessage at 0x7eff831a1f30>)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extract the downloaded file**"
      ],
      "metadata": {
        "id": "FGt9OzRSr8pr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Once the model file is downloaded as a compressed file (shape_predictor_68_face_landmarks.dat.bz2), the code extracts it to obtain the actual model file (shape_predictor_68_face_landmarks.dat). This step is necessary to ensure that the model file is in the correct format for dlib to load."
      ],
      "metadata": {
        "id": "cdn5gbfQsnSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Extracting shape predictor model file...\")\n",
        "with bz2.open(model_path_bz2, \"rb\") as f_in:\n",
        "    with open(model_path_dat, \"wb\") as f_out:\n",
        "        shutil.copyfileobj(f_in, f_out)\n",
        "os.remove(model_path_bz2)\n",
        "print(\"Shape predictor model file downloaded and extracted successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2z9YxGtr8_N",
        "outputId": "b155522c-ba41-4180-d595-8e961a749953"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting shape predictor model file...\n",
            "Shape predictor model file downloaded and extracted successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import dlib\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "iB7l7eZfqzNG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load the pre-trained facial landmark detector**"
      ],
      "metadata": {
        "id": "zUlxziSrrpCk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "detector = dlib.get_frontal_face_detector()\n",
        "try:\n",
        "    predictor = dlib.shape_predictor(model_path_dat)\n",
        "except Exception as e:\n",
        "    print(\"Error loading the shape predictor model:\", e)\n",
        "    exit()"
      ],
      "metadata": {
        "id": "6J2QcJfNrqEm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function to detect eye landmarks**"
      ],
      "metadata": {
        "id": "_ccdTsIerrAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_eyes(frame):\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    faces = detector(gray)\n",
        "    for face in faces:\n",
        "        landmarks = predictor(gray, face)\n",
        "        left_eye = []\n",
        "        right_eye = []\n",
        "        for n in range(36, 42): # Left eye landmarks\n",
        "            x = landmarks.part(n).x\n",
        "            y = landmarks.part(n).y\n",
        "            left_eye.append((x, y))\n",
        "        for n in range(42, 48): # Right eye landmarks\n",
        "            x = landmarks.part(n).x\n",
        "            y = landmarks.part(n).y\n",
        "            right_eye.append((x, y))\n",
        "        return left_eye, right_eye\n",
        "    return None, None"
      ],
      "metadata": {
        "id": "hKvea8Dxrurp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Main function**"
      ],
      "metadata": {
        "id": "CbedsfxLsL-n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The program starts capturing video from the default camera (usually the webcam) using OpenCV's VideoCapture() function. It continuously processes each frame of the video stream.For each frame, the code detects faces using the dlib frontal face detector (get_frontal_face_detector()) and then uses the shape predictor model to detect landmarks for each detected face. Specifically, it detects the landmarks corresponding to the left and right eyes."
      ],
      "metadata": {
        "id": "5Q6FxDb1stex"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "C3ScrWySoHWD"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    cap = cv2.VideoCapture(0)\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        left_eye, right_eye = detect_eyes(frame)\n",
        "        if left_eye and right_eye:\n",
        "            # Draw left eye landmarks\n",
        "            for (x, y) in left_eye:\n",
        "                cv2.circle(frame, (x, y), 2, (0, 255, 0), -1)\n",
        "            # Draw right eye landmarks\n",
        "            for (x, y) in right_eye:\n",
        "                cv2.circle(frame, (x, y), 2, (0, 255, 0), -1)\n",
        "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        plt.imshow(frame_rgb)\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "    cap.release()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " the code successfully detects eye landmarks for a frame, it draws green circles around the detected landmarks for both eyes. It then displays the annotated frame using matplotlib's imshow() function within the notebook. This provides a visual representation of where the eyes are located in the frame.\n",
        "User Interaction: While the video stream is being displayed, you can press the 'q' key on your keyboard to quit the program and close the video stream."
      ],
      "metadata": {
        "id": "VadgAT4Ms25n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "vE2fgY4fuSTc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Test the model without camera**"
      ],
      "metadata": {
        "id": "vDse248TtLTO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load a static image**\n",
        "Can be done either way:\n",
        "\n",
        "*   Upload an image to /content/ directory of Google colab.\n",
        "*   Enter a path to a sample image on your PC.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QPan40lquOys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/meytiii/Deep-Learning/blob/main/datasets/sample-image.jpg?raw=true\n",
        "#Remember to change the name to sample-image.jpg (Remove the \"?raw=true\" at the end)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ui5kfXj6z4r5",
        "outputId": "5427c075-aebe-46bb-9cf6-db5fc8a801ea"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-03 10:09:12--  https://github.com/meytiii/Deep-Learning/blob/main/datasets/sample-image.jpg?raw=true\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/meytiii/Deep-Learning/raw/main/datasets/sample-image.jpg [following]\n",
            "--2024-05-03 10:09:13--  https://github.com/meytiii/Deep-Learning/raw/main/datasets/sample-image.jpg\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/meytiii/Deep-Learning/main/datasets/sample-image.jpg [following]\n",
            "--2024-05-03 10:09:13--  https://raw.githubusercontent.com/meytiii/Deep-Learning/main/datasets/sample-image.jpg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2573364 (2.5M) [image/jpeg]\n",
            "Saving to: ‘sample-image.jpg?raw=true’\n",
            "\n",
            "sample-image.jpg?ra 100%[===================>]   2.45M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-05-03 10:09:13 (25.6 MB/s) - ‘sample-image.jpg?raw=true’ saved [2573364/2573364]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/sample-image.jpg\"\n",
        "frame = cv2.imread(image_path)"
      ],
      "metadata": {
        "id": "kUwlIj-nufVs"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Perform eye landmark detection on the image**"
      ],
      "metadata": {
        "id": "lLK86kmauvmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "left_eye, right_eye = detect_eyes(frame)"
      ],
      "metadata": {
        "id": "8NuIuBA0uzht"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualize the results (draw circles around the detected eye landmarks)**"
      ],
      "metadata": {
        "id": "x9Ao6u6yu1Ri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if left_eye and right_eye:\n",
        "    for (x, y) in left_eye:\n",
        "        cv2.circle(frame, (x, y), 2, (0, 255, 0), -1)\n",
        "    for (x, y) in right_eye:\n",
        "        cv2.circle(frame, (x, y), 2, (0, 255, 0), -1)"
      ],
      "metadata": {
        "id": "2aYK_PVbu29h"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Display the annotated image**"
      ],
      "metadata": {
        "id": "yKH_49ipu47E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "cv2_imshow(frame)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "Xbd7C5Zvu52k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**As you can see our model framed the person's eyes with green dots so we know that our model is working correctly.**"
      ],
      "metadata": {
        "id": "q2CE_foluHP_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save the trained shape predictor model to a file using pickle**"
      ],
      "metadata": {
        "id": "swhf8U55sUif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"eye_tracking_model.pkl\", \"wb\") as f:\n",
        "    pickle.dump(predictor, f)"
      ],
      "metadata": {
        "id": "dbihB6-MsPd1"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load the saved shape predictor model from the file using pickle**\n",
        "\n",
        "\n",
        "*   For later use...\n",
        "\n"
      ],
      "metadata": {
        "id": "ZxiqZfSOsV9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"eye_tracking_model.pkl\", \"rb\") as f:\n",
        "    predictor = pickle.load(f)"
      ],
      "metadata": {
        "id": "bM9WX20jsSpU"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}