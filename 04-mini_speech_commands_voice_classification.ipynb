{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Import the necessary libraries**"
      ],
      "metadata": {
        "id": "a0sDpJ6EIOta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models"
      ],
      "metadata": {
        "id": "JTmxm9AiIRc-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Set the seed value for experiment reproducibility.**"
      ],
      "metadata": {
        "id": "beqZwCxMISlz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 42\n",
        "tf.random.set_seed(seed)\n",
        "np.random.seed(seed)"
      ],
      "metadata": {
        "id": "R8g6ag75IUb3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download and extract the dataset from Tensorflow's Mini Speech Commands dataset**"
      ],
      "metadata": {
        "id": "fUayoUhRIW7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_PATH = '/content/mini_speech_commands'\n",
        "#Since im using colab for this, the path is set like this,\n",
        "#feel free to change the path if you're running on your own PC.\n",
        "if not os.path.exists(DATASET_PATH):\n",
        "    tf.keras.utils.get_file(\n",
        "        'mini_speech_commands.zip',\n",
        "        origin=\"http://storage.googleapis.com/download.tensorflow.org/data/mini_speech_commands.zip\",\n",
        "        extract=True,\n",
        "        cache_dir='/content/',\n",
        "        cache_subdir='.')"
      ],
      "metadata": {
        "id": "Kzs58VIhIWOo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "commands = os.listdir(DATASET_PATH)\n",
        "commands = [cmd for cmd in commands if os.path.isdir(os.path.join(DATASET_PATH, cmd))]"
      ],
      "metadata": {
        "id": "GQypnIf-ItlY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocess the audio data**"
      ],
      "metadata": {
        "id": "pmG_wTCPIvcF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_audio(audio, labels):\n",
        "    audio = tf.squeeze(audio, axis=-1)\n",
        "    return audio, labels"
      ],
      "metadata": {
        "id": "J9VAHpxhIw9Y"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load and preprocess the training and validation datasets**"
      ],
      "metadata": {
        "id": "OgKwnTtvI2fD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds, val_ds = tf.keras.utils.audio_dataset_from_directory(\n",
        "    directory=DATASET_PATH,\n",
        "    batch_size=64,\n",
        "    validation_split=0.2,\n",
        "    seed=0,\n",
        "    output_sequence_length=16000,\n",
        "    subset='both')\n",
        "\n",
        "train_ds = train_ds.map(preprocess_audio, tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.map(preprocess_audio, tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "u9OHA90rI38m",
        "outputId": "af2e2889-ea8b-45d5-a703-0b07c6c6b41e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8000 files belonging to 8 classes.\n",
            "Using 6400 files for training.\n",
            "Using 1600 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now time to define the model architecture**\n",
        "\n",
        "*   We want the inputs in shapes of 16000 items.\n",
        "*   Activation is set to 'relu'\n",
        "\n"
      ],
      "metadata": {
        "id": "ZoI1jzPCI89v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (16000,)\n",
        "num_labels = len(commands)\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=input_shape),\n",
        "    layers.Reshape((16000, 1)),\n",
        "    layers.Conv1D(32, 3, activation='relu'),\n",
        "    layers.Conv1D(64, 3, activation='relu'),\n",
        "    layers.MaxPooling1D(),\n",
        "    layers.Dropout(0.25),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(num_labels),\n",
        "])"
      ],
      "metadata": {
        "id": "m1yTfSi4I8f8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compiling and then training the model.**"
      ],
      "metadata": {
        "id": "xv1-wlO1JMbB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy'],\n",
        ")"
      ],
      "metadata": {
        "id": "Y0546tC4JQtg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, patience=2),\n",
        ")"
      ],
      "metadata": {
        "id": "izBPjRZ3JSIA",
        "outputId": "3bcc4aca-1ee6-481f-cdae-9e3ac962d348",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "100/100 [==============================] - 13s 109ms/step - loss: 1.9635 - accuracy: 0.2289 - val_loss: 1.8092 - val_accuracy: 0.3194\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 11s 102ms/step - loss: 1.6826 - accuracy: 0.3623 - val_loss: 1.6600 - val_accuracy: 0.4131\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 1.3894 - accuracy: 0.4794 - val_loss: 1.4958 - val_accuracy: 0.4812\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 1.0984 - accuracy: 0.6050 - val_loss: 1.5116 - val_accuracy: 0.4825\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 11s 104ms/step - loss: 0.8910 - accuracy: 0.6936 - val_loss: 1.5640 - val_accuracy: 0.5069\n",
            "Epoch 5: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate the model**\n",
        "\n",
        "*   Finally we are going to evaluate our created model and see the test results.\n",
        "*   This includes the Loss and Accuracy of our model.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nchVKr7kJYyB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds = val_ds.take(1)\n",
        "test_results = model.evaluate(test_ds, return_dict=True)\n",
        "print(\"Test Loss:\", test_results['loss'])\n",
        "print(\"Test Accuracy:\", test_results['accuracy'])"
      ],
      "metadata": {
        "id": "GMtownWhJo6E",
        "outputId": "bd91fdd5-f197-4bdd-c464-a4f29057467a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 84ms/step - loss: 1.8548 - accuracy: 0.3438\n",
            "Test Loss: 1.8547708988189697\n",
            "Test Accuracy: 0.34375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Export the model**"
      ],
      "metadata": {
        "id": "0vWCnu6QJ2OU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can export our created model and use it elsewhere."
      ],
      "metadata": {
        "id": "HyV3sdGGJ6Qr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/sound_classification_model\")"
      ],
      "metadata": {
        "id": "zaIge7DcJ19l"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}