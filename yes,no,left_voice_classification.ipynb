{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Set the seed value for experiment reproducibility.\n",
        "seed = 42\n",
        "tf.random.set_seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Define the path to the dataset\n",
        "DATASET_PATH = '/content/mini_speech_commands'\n",
        "\n",
        "# Download the dataset\n",
        "if not os.path.exists(DATASET_PATH):\n",
        "    tf.keras.utils.get_file(\n",
        "        'mini_speech_commands.zip',\n",
        "        origin=\"http://storage.googleapis.com/download.tensorflow.org/data/mini_speech_commands.zip\",\n",
        "        extract=True,\n",
        "        cache_dir='/content/',\n",
        "        cache_subdir='.')\n",
        "\n",
        "# Define the commands\n",
        "commands = os.listdir(DATASET_PATH)\n",
        "commands = [cmd for cmd in commands if os.path.isdir(os.path.join(DATASET_PATH, cmd))]\n",
        "\n",
        "# Function to preprocess the audio data\n",
        "def preprocess_audio(audio, labels):\n",
        "    audio = tf.squeeze(audio, axis=-1)\n",
        "    return audio, labels\n",
        "\n",
        "# Load and preprocess the training and validation datasets\n",
        "train_ds, val_ds = tf.keras.utils.audio_dataset_from_directory(\n",
        "    directory=DATASET_PATH,\n",
        "    batch_size=64,\n",
        "    validation_split=0.2,\n",
        "    seed=0,\n",
        "    output_sequence_length=16000,\n",
        "    subset='both')\n",
        "\n",
        "train_ds = train_ds.map(preprocess_audio, tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.map(preprocess_audio, tf.data.AUTOTUNE)\n",
        "\n",
        "# Define the model architecture\n",
        "input_shape = (16000,)\n",
        "num_labels = len(commands)\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=input_shape),\n",
        "    layers.Reshape((16000, 1)),\n",
        "    layers.Conv1D(32, 3, activation='relu'),\n",
        "    layers.Conv1D(64, 3, activation='relu'),\n",
        "    layers.MaxPooling1D(),\n",
        "    layers.Dropout(0.25),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(num_labels),\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "EPOCHS = 10\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, patience=2),\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_ds = val_ds.take(1)\n",
        "test_results = model.evaluate(test_ds, return_dict=True)\n",
        "print(\"Test Loss:\", test_results['loss'])\n",
        "print(\"Test Accuracy:\", test_results['accuracy'])\n",
        "\n",
        "# Save the model\n",
        "model.save(\"/content/sound_classification_model\")\n",
        "\n",
        "print(\"Model training and evaluation completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5vqkS2uEWJo",
        "outputId": "3b619436-7003-475d-e5a2-c448ddaa3003"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8000 files belonging to 8 classes.\n",
            "Using 6400 files for training.\n",
            "Using 1600 files for validation.\n",
            "Epoch 1/10\n",
            " 39/100 [==========>...................] - ETA: 3:50 - loss: 2.0873 - accuracy: 0.1695"
          ]
        }
      ]
    }
  ]
}